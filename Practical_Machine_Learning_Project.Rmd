---
title: "Practical Machine Learning Project"
author: "Alfred Homere Ngandam Mfomdoum"
date: "September 4, 2016"
output: html_document
---
## Introduction

The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. we may use any of the other variables to predict with. we should create a report describing how we built our model, how we used cross validation, what we think the expected out of sample error is, and why we made the choices. We will also use our prediction model to predict 20 different test cases.

## Data Sources

The training data for this project are available here:

- https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

- https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

## Libraries used

the following libraries were used for this project
* library(caret)
* library(rpart)
* library(rpart.plot)
* library(RColorBrewer)
* library(rattle)
* library(randomForest)
** Note: Depending on the version of my r software, 3.1.1, some errors appeared during the execution due to these different packages. We then choose to install some others as and as we need them in the project.

## Getting the data

The training data set can be found on the following URL:

```{r, include=TRUE}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
knitr::opts_chunk$set(echo = TRUE)
```

The testing data set can be found on the following URL:

```{r, include=TRUE}
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the data from the directory

```{r, include=TRUE}
getwd()
"C:./Users/ngandamh/Documents/Coursera/Practical_Machine_Learning/Week4/Project"
DaSetTraining <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
DaSetTesting <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
knitr::opts_chunk$set(echo = TRUE)
```

## Partitioning the training set into two

```{r, include=TRUE}
library("caret")
inTrain <- createDataPartition(y=DaSetTraining$classe, p=0.6, list=FALSE)
myTraining <- DaSetTraining[inTrain, ]; myTesting <- DaSetTraining[-inTrain, ]
dim(myTraining); dim(myTesting)
knitr::opts_chunk$set(echo = TRUE)
```

## Cleaning the data

```{r, include=TRUE}
myDataNZV <- nearZeroVar(myTraining, saveMetrics=TRUE)
knitr::opts_chunk$set(echo = TRUE)
```

## Running the code to create another subset without NZV variables

```{r, include=TRUE}
myNZVvars <- names(myTraining) %in% c("new_window", "kurtosis_roll_belt", "kurtosis_picth_belt",
                                      "kurtosis_yaw_belt", "skewness_roll_belt", "skewness_roll_belt.1", "skewness_yaw_belt",
                                      "max_yaw_belt", "min_yaw_belt", "amplitude_yaw_belt", "avg_roll_arm", "stddev_roll_arm",
                                      "var_roll_arm", "avg_pitch_arm", "stddev_pitch_arm", "var_pitch_arm", "avg_yaw_arm",
                                      "stddev_yaw_arm", "var_yaw_arm", "kurtosis_roll_arm", "kurtosis_picth_arm",
                                      "kurtosis_yaw_arm", "skewness_roll_arm", "skewness_pitch_arm", "skewness_yaw_arm",
                                      "max_roll_arm", "min_roll_arm", "min_pitch_arm", "amplitude_roll_arm", "amplitude_pitch_arm",
                                      "kurtosis_roll_dumbbell", "kurtosis_picth_dumbbell", "kurtosis_yaw_dumbbell", "skewness_roll_dumbbell",
                                      "skewness_pitch_dumbbell", "skewness_yaw_dumbbell", "max_yaw_dumbbell", "min_yaw_dumbbell",
                                      "amplitude_yaw_dumbbell", "kurtosis_roll_forearm", "kurtosis_picth_forearm", "kurtosis_yaw_forearm",
                                      "skewness_roll_forearm", "skewness_pitch_forearm", "skewness_yaw_forearm", "max_roll_forearm",
                                      "max_yaw_forearm", "min_roll_forearm", "min_yaw_forearm", "amplitude_roll_forearm",
                                      "amplitude_yaw_forearm", "avg_roll_forearm", "stddev_roll_forearm", "var_roll_forearm",
                                      "avg_pitch_forearm", "stddev_pitch_forearm", "var_pitch_forearm", "avg_yaw_forearm",
                                      "stddev_yaw_forearm", "var_yaw_forearm")
myTraining <- myTraining[!myNZVvars]
knitr::opts_chunk$set(echo = TRUE)
```

## To check the new NA of observations

```{r, include=TRUE}
dim(myTraining)
knitr::opts_chunk$set(echo = TRUE)
```

## Killing first column of Dataset - ID Removing first ID variable so that it does not interfer with ML Algorithm

```{r, include=TRUE}
myTraining <- myTraining[c(-1)]
knitr::opts_chunk$set(echo = TRUE)
```

## Cleaning Variables with too many NAs. For Variables that have more than a 60% threshold of NA's I'm going to leave them out

```{r, include=TRUE}
trainingV3 <- myTraining #creating another subset to iterate in loop
for(i in 1:length(myTraining)) { #for every column in the training dataset
  if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .6 ) { #if n?? NAs > 60% of total observations
    for(j in 1:length(trainingV3)) {
      if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) ==1)  { #if the columns are the same:
        trainingV3 <- trainingV3[ , -j] #Remove that column
      }   
    } 
  }
}
dim(trainingV3)

knitr::opts_chunk$set(echo = TRUE)
```

##Seting back to our set

```{r, include=TRUE}
myTraining <- trainingV3
rm(trainingV3)
knitr::opts_chunk$set(echo = TRUE)
```

# Now let us do the exact same 3 transformations but for our myTesting and testing data sets.

```{r, include=TRUE}
clean1 <- colnames(myTraining)
clean2 <- colnames(myTraining[, -58]) #already with classe column removed
myTesting <- myTesting[clean1]
DaSetTesting <- DaSetTesting[clean2]
knitr::opts_chunk$set(echo = TRUE)
```

## To check the new NA of observations

```{r, include=TRUE}
dim(myTesting)
knitr::opts_chunk$set(echo = TRUE)
```

##To check the new NA of observations

```{r, include=TRUE}
dim(DaSetTesting)
knitr::opts_chunk$set(echo = TRUE)
```

* Note: The last column - problem_id - which is not equal to training sets, was also "automagically" removed
 No need for this code:
 testing <- testing[-length(testing)]

In order to ensure proper functioning of Decision Trees and especially RandomForest Algorithm with the Test data set (data set provided), we need to coerce the data into the same type.

```{r, include=TRUE}
for (i in 1:length(DaSetTesting) ) {
  for(j in 1:length(myTraining)) {
    if( length( grep(names(myTraining[i]), names(DaSetTesting)[j]) ) ==1)  {
      class(DaSetTesting[j]) <- class(myTraining[i])
    }      
  }      
}
knitr::opts_chunk$set(echo = TRUE)
```

And to make sure Coertion really worked, simple smart as technique:

```{r, include=TRUE}
DaSetTesting <- rbind(myTraining[2, -58] , DaSetTesting) 
DaSetTesting <- DaSetTesting[-1,]
knitr::opts_chunk$set(echo = TRUE)
```

* Note row 2 does not mean anything, this will be removed right now:

## Using ML algorithms for prediction: Decision Tree

```{r, include=TRUE}
library("rpart")
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
knitr::opts_chunk$set(echo = TRUE)
```

#to view the decision tree with fancy run this command:

```{r, include=TRUE}
library("rattle")
fancyRpartPlot(modFitA1)
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting

```{r, include=TRUE}
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
knitr::opts_chunk$set(echo = TRUE)
```

# Using confusion Matrix to test results:

```{r, include=TRUE}
confusionMatrix(predictionsA1, myTesting$classe)
knitr::opts_chunk$set(echo = TRUE)
```

# Using ML algorithms for prediction: Random Forests

```{r, include=TRUE}
library("randomForest")
modFitB1 <- randomForest(classe ~. , data=myTraining)
modFitB1
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting in-sample error:

```{r, include=TRUE}
  predictionsB1 <- predict(modFitB1, myTesting, type = "class")
knitr::opts_chunk$set(echo = TRUE)
```


## Using confusion Matrix to test results:

```{r, include=TRUE}
  confusionMatrix(predictionsB1, myTesting$classe)
knitr::opts_chunk$set(echo = TRUE)
```

## Generating Files to submit as answers for the Assignment:

Finally, using the provided Test Set out-of-sample error.
For Random Forests we use the following formula, which yielded a much better prediction in in-sample:
#### Apply the prediction model

```{r, include=TRUE}
predictionsB2 <- predict(modFitB1, DaSetTesting, type = "class")
predictionsB2
knitr::opts_chunk$set(echo = TRUE)
```

# Function to generate files with predictions to submit for assignment

```{r, include=TRUE}
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictionsB2)
knitr::opts_chunk$set(echo = TRUE)
```
